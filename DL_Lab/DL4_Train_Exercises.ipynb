{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wzvwiv0lUfxi"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L1mnXsWUfnC0"
   },
   "source": [
    "We will finally put all the pieces together and train our MLP to classify the FashionMNIST dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FYU_4Jxz865H"
   },
   "source": [
    "# Previously"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dvp2zO-wYWXK"
   },
   "source": [
    "Remember that we already have our data and model classes ready from previous notebooks. Let us repeat the code here for convenience. If you have completed the previous notebooks you should be very familiar with this code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BDgeJ9KQYm6t"
   },
   "source": [
    "### Data Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "totnmzwWYIXv"
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "class DataModule():\n",
    "\n",
    "    def __init__(self, batch_size=64):\n",
    "        self.batch_size = batch_size # size of the batches\n",
    "\n",
    "    def get_dataloader(self, train):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        # returns train dataloader\n",
    "        return self.get_dataloader(train=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        # returns test dataloader\n",
    "        return self.get_dataloader(train=False)\n",
    "\n",
    "class FashionMNIST(DataModule):\n",
    "\n",
    "    def __init__(self, root, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                        transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "        self.train = datasets.FashionMNIST(root=root, train=True, download=True, transform=transform)\n",
    "        self.val = datasets.FashionMNIST(root=root, train=False, download=True, transform=transform)\n",
    "\n",
    "    def get_dataloader(self, train):\n",
    "        data = self.train if train else self.val\n",
    "        return torch.utils.data.DataLoader(data, self.batch_size, shuffle=train)\n",
    "\n",
    "    def text_classes(self, indices):\n",
    "        label_list = ['t-shirt/top', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\n",
    "        return [label_list[int(i)] for i in indices]\n",
    "\n",
    "    def visualize(self, X, y, nrows=1, ncols=5):\n",
    "        labels = self.text_classes(y)\n",
    "        self.show_images(X.squeeze(1), nrows, ncols, titles=labels)\n",
    "\n",
    "    def show_images(self, imgs, num_rows, num_cols, titles, scale=1.5):\n",
    "        figsize = (num_cols * scale, num_rows * scale)\n",
    "        _, axes = plt.subplots(num_rows, num_cols, figsize=figsize)\n",
    "        axes = axes.flatten()\n",
    "        for i, (ax, img) in enumerate(zip(axes, imgs)):\n",
    "            img = img.squeeze().numpy()\n",
    "            ax.imshow(img, cmap='Greys_r')\n",
    "            ax.axes.get_xaxis().set_visible(False)\n",
    "            ax.axes.get_yaxis().set_visible(False)\n",
    "            ax.set_title(titles[i])\n",
    "        return axes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FzxOCB-hPyn4"
   },
   "source": [
    "### MLP from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rXlkMhFCP-Y9"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MLPScratch(nn.Module):\n",
    "    def __init__(self, num_inputs, num_outputs, num_hiddens, lr=0.01, sigma=0.01):\n",
    "        super().__init__()\n",
    "        self.num_inputs = num_inputs\n",
    "        self.num_outputs = num_outputs\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.lr = lr\n",
    "\n",
    "        self.W1 = nn.Parameter(torch.randn(num_inputs, num_hiddens) * sigma)\n",
    "        self.b1 = nn.Parameter(torch.zeros(num_hiddens))\n",
    "        self.W2 = nn.Parameter(torch.randn(num_hiddens, num_outputs) * sigma)\n",
    "        self.b2 = nn.Parameter(torch.zeros(num_outputs))\n",
    "\n",
    "    def forward(self, X):\n",
    "        H = F.relu(torch.matmul(X, self.W1) + self.b1)\n",
    "        return torch.matmul(H, self.W2) + self.b2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sgsyeYL8QGh2"
   },
   "source": [
    "# Start Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pTCkQEcPQlkr"
   },
   "source": [
    "Now we want to create our `data` and `model` objects from our classes `FashionMNIST` and `MLPScratch`. Before we start we just need to pay attention to a small detail. Our input data consists of images of 28Ã—28 that cannot be fed as an input to our MLP. We will ignore the spatial structure in our data and just consider each pixel as a feature. So, make sure to set the number of inputs of our MLP accordingly. For the number of hidden units use 256.\n",
    "\n",
    "Additionally create an `optimizer` with `torch.optim.SGD` with learning rate 0.1. As `criterion` use the `CrossEntropyLoss()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6s4ei_OzYvvo"
   },
   "outputs": [],
   "source": [
    "# Exercise\n",
    "data =\n",
    "model =\n",
    "optimizer =\n",
    "criterion ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bKNpX80a6Eps"
   },
   "source": [
    "Make sure you are able to run the following cell. Note that we need to reshape our input before calling `forward` (make sure you understand why)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RliKAIq-3mTi"
   },
   "outputs": [],
   "source": [
    "X,y = next(iter(data.train_dataloader()))\n",
    "output = model(X.reshape(-1,model.num_inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KGZWekSx38Vd"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7UdFuCVBRIlu"
   },
   "source": [
    "Now it is time to create our training loop. You have already done each step separately, now it is time to put them together. Make sure your loss is decreasing at each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 102320,
     "status": "ok",
     "timestamp": 1693784993869,
     "user": {
      "displayName": "Filipa Valdeira",
      "userId": "09399709566484677368"
     },
     "user_tz": -60
    },
    "id": "6vF3LGug6N1f",
    "outputId": "38ad7728-ca1a-4496-f49f-fece089e5017"
   },
   "outputs": [],
   "source": [
    "# Exercise - complete the code with the training loop.\n",
    "# You only need one line of code after each comment\n",
    "\n",
    "max_epochs = 5 # number of epochs\n",
    "\n",
    "# Loop over the epochs\n",
    "for\n",
    "\n",
    "    running_loss = 0\n",
    "\n",
    "    # Loop over the train dataloader\n",
    "    for\n",
    "\n",
    "        # Forward\n",
    "\n",
    "\n",
    "        # Compute the loss with criterion\n",
    "\n",
    "\n",
    "        # Remember to zero the gradients\n",
    "\n",
    "\n",
    "        # Backward\n",
    "\n",
    "\n",
    "        # Optimizer step\n",
    "\n",
    "        # update the loss\n",
    "        running_loss += loss.item() # update the loss\n",
    "\n",
    "    print(f\"Finished epoch {epoch+1} : current training loss is {running_loss/len(data.train_dataloader())}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IBJOscq55Vjr"
   },
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wEke7byyF-zb"
   },
   "source": [
    "Let us inspect a bit closer the predictions for a batch of our model. We will take the validation dataset and do a forward pass to get the values of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zrAZ9pq0SjB2"
   },
   "outputs": [],
   "source": [
    "# Exercise take one batch of the validation dataset and get the predicted classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BtUsV2H08pXb"
   },
   "source": [
    "Plot the predictions and true data for some images of this batch (remember that you can use `data.visualize`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158
    },
    "executionInfo": {
     "elapsed": 661,
     "status": "ok",
     "timestamp": 1693785058538,
     "user": {
      "displayName": "Filipa Valdeira",
      "userId": "09399709566484677368"
     },
     "user_tz": -60
    },
    "id": "4qGh1k7g-2Pr",
    "outputId": "f1ffa892-e1a3-4a18-f6cd-90879048984d"
   },
   "outputs": [],
   "source": [
    "# exercise plot true and predicted y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s8wn2Yx19KWn"
   },
   "source": [
    "Complete the following code to get the accuracy on the validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3020,
     "status": "ok",
     "timestamp": 1693785064293,
     "user": {
      "displayName": "Filipa Valdeira",
      "userId": "09399709566484677368"
     },
     "user_tz": -60
    },
    "id": "PHLwC8n49LOz",
    "outputId": "37542197-11c6-4630-921f-44e2d627e051"
   },
   "outputs": [],
   "source": [
    "correct_samples = 0\n",
    "\n",
    "for X, y in data.val_dataloader():\n",
    "    with torch.no_grad():\n",
    "        # Get the predictions\n",
    "        preds =\n",
    "\n",
    "        # Update number of correct_samples\n",
    "        correct_samples +=\n",
    "\n",
    "acc = correct_samples/len(data.val_dataloader().dataset)\n",
    "print(f'Accuracy in validation dataset {acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bphAJINAAuoJ"
   },
   "source": [
    "# MLP using PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nG3q5sAUFaaY"
   },
   "source": [
    "As you may imagine, we do not wish to specify weights and bias for each layer of our network from now on. The implementation of our MLP was only done for didatic purposes. A more concise implementation could be done using [`nn.Linear`](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html). You just need to create two fully connected layers with the correct number of inputs and outputs. In the forward method, you will directly call those layers with manually computing from weights and bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n6mSrhXx-ev0"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, num_inputs, num_outputs, num_hiddens, lr=0.01, sigma=0.01):\n",
    "        super().__init__()\n",
    "        self.num_inputs = num_inputs\n",
    "        self.num_outputs = num_outputs\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.lr = lr\n",
    "\n",
    "        # exercise - create the two fully connected layers\n",
    "        self.fc1 =\n",
    "        self.fc2 =\n",
    "\n",
    "    def forward(self, X):\n",
    "      # Exercise - implement the forward method\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BRD1SswfHGhE"
   },
   "source": [
    "You can repeat the training to make sure your class is working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CPUgeQC4G2FK"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPnSHRTYgU805nH9ZROm6Ia",
   "collapsed_sections": [
    "FYU_4Jxz865H"
   ],
   "provenance": [
    {
     "file_id": "1wRzkMkHVP_Mp8pv5_Vnldo4qWSfRz6A8",
     "timestamp": 1693785096101
    },
    {
     "file_id": "18JCI7NJQ8apUKGs8-evyonlywMYECxB_",
     "timestamp": 1693764176228
    },
    {
     "file_id": "1fxlvsNuYLOv6K4sqVzTGXHpB_I1R0bBU",
     "timestamp": 1693144873463
    },
    {
     "file_id": "1FPQAIs5f3OgaWy1TZ7ILnCKWf3kES-NK",
     "timestamp": 1693142496119
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
